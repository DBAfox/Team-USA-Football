{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Team USA Football](images/Usa_football_body_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This projects mission was to build a model that can determine what contributes to a football players sucess on the field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "Foxy Stats was hired to perform data analysis for Team USA. Flag Football is coming to the 2028 Olympic Games in LA and they need the best our country has to offer. While the NFL is full contact\n",
    "they are still some of the players in the United States. We are to find the best of the best to help fill in some gaps in the team "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding and Limitations\n",
    "The data comes from nflverse via their [GitHub](https://github.com/nflverse/nflverse-data/releases). The initial data contains offensive stats from 1999 to 2023. It is updated on a weekly basis during the football season and after any stat is corrected as well.  \n",
    "\n",
    "Data Dictionary available to help better understand these stats [here](https://nflreadr.nflverse.com/articles/dictionary_player_stats.html)\n",
    "\n",
    "Limitations include no record of win or loss. No record of defensive stats to paint a fuller picture. No record of lineman performance upon a sack or rushing negative yards, fumble, etc  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "- Exploratory Data Analysis\n",
    "    - Feature Engineering\n",
    "- Modeling and Evaluating\n",
    "    - DecisionTree\n",
    "    - Random Forest Classifier (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ill save my data as some new dataframes and see what i have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.read_csv('data/player_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ill start with stats_df as that will require more work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check up on Aaron Rodgers\n",
    "stats_df[stats_df['player_display_name'] == 'Aaron Rodgers'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 1 to show all info in cell below then comment it out and use 2 to go back to default view I can delete this later\n",
    "\n",
    "#1\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#2\n",
    "#pd.reset_option('display.max_rows')\n",
    "#pd.reset_option('display.max_columns')\n",
    "#pd.reset_option('display.max_colwidth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ive only got offensive related stats going back to 1999. I wont be needing those older players in a team for today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the last ten years of data \n",
    "stats_df = stats_df[stats_df['season'].isin(range(2014, 2024))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the regular season so we can see every player in action. this is about players not teams\n",
    "stats_df = stats_df[stats_df['season_type'] == 'REG']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working solely with the offense seperate by position for our 3 analyses\n",
    "# Filter for quarterbacks\n",
    "qbs_df = stats_df[stats_df['position'] == 'QB']\n",
    "\n",
    "# Filter for rushers (RBs and FBs)\n",
    "rushers_df = stats_df[stats_df['position'].isin(['RB', 'FB', 'HB'])]\n",
    "\n",
    "# Filter for receivers (WRs and TEs)\n",
    "receivers_df = stats_df[stats_df['position'].isin(['WR', 'TE'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QB metrics\n",
    "qbs_df.loc[:, 'completion_percentage'] = qbs_df['completions'] / qbs_df['attempts']\n",
    "qbs_df.loc[:, 'yards_per_attempt'] = qbs_df['passing_yards'] / qbs_df['attempts']\n",
    "qbs_df.loc[:, 'pass_tds_per_attempt'] = qbs_df['passing_tds'] / qbs_df['attempts']\n",
    "qbs_df.loc[:, 'season_passing_yards'] = qbs_df.groupby(['player_id', 'season'])['passing_yards'].transform('sum')\n",
    "qbs_df.loc[:, 'season_passing_tds'] = qbs_df.groupby(['player_id', 'season'])['passing_tds'].transform('sum')\n",
    "qbs_df.loc[:, 'season_pass_attempts'] = qbs_df.groupby(['player_id', 'season'])['attempts'].transform('sum')\n",
    "qbs_df.loc[:, 'season_completions'] = qbs_df.groupby(['player_id', 'season'])['completions'].transform('sum')\n",
    "qbs_df.loc[:, 'season_completion_percentage'] = qbs_df.groupby(['player_id', 'season'])['completion_percentage'].transform('mean')\n",
    "qbs_df.loc[:, 'season_yards_per_attempt'] = qbs_df.groupby(['player_id', 'season'])['yards_per_attempt'].transform('mean')\n",
    "qbs_df.loc[:, 'season_pass_tds_per_attempt'] = qbs_df.groupby(['player_id', 'season'])['pass_tds_per_attempt'].transform('mean')\n",
    "\n",
    "# Rusher metrics\n",
    "rushers_df.loc[:, 'yards_per_carry'] = rushers_df['rushing_yards'] / rushers_df['carries']\n",
    "rushers_df.loc[:, 'tds_per_carry'] = rushers_df['rushing_tds'] / rushers_df['carries']\n",
    "rushers_df.loc[:, 'season_rushing_tds'] = rushers_df.groupby(['player_id', 'season'])['rushing_tds'].transform('sum')\n",
    "rushers_df.loc[:, 'season_rushing_yards'] = rushers_df.groupby(['player_id', 'season'])['rushing_yards'].transform('sum')\n",
    "rushers_df.loc[:, 'season_carries'] = rushers_df.groupby(['player_id', 'season'])['carries'].transform('sum')\n",
    "rushers_df.loc[:, 'season_yards_per_carry'] = rushers_df.groupby(['player_id', 'season'])['yards_per_carry'].transform('mean')\n",
    "rushers_df.loc[:, 'season_tds_per_carry'] = rushers_df.groupby(['player_id', 'season'])['tds_per_carry'].transform('mean')\n",
    "\n",
    "# Receiver metrics\n",
    "receivers_df.loc[:, 'yards_per_reception'] = receivers_df['receiving_yards'] / receivers_df['receptions']\n",
    "receivers_df.loc[:, 'season_receiving_yards'] = receivers_df.groupby(['player_id', 'season'])['receiving_yards'].transform('sum')\n",
    "receivers_df.loc[:, 'tds_per_reception'] = receivers_df['receiving_tds'] / receivers_df['receptions']\n",
    "receivers_df.loc[:, 'season_receiving_tds'] = receivers_df.groupby(['player_id', 'season'])['receiving_tds'].transform('sum')\n",
    "receivers_df.loc[:, 'season_receptions'] = receivers_df.groupby(['player_id', 'season'])['receptions'].transform('sum')\n",
    "receivers_df.loc[:, 'season_yards_per_reception'] = receivers_df.groupby(['player_id', 'season'])['yards_per_reception'].transform('mean')\n",
    "receivers_df.loc[:, 'season_tds_per_reception'] = receivers_df.groupby(['player_id', 'season'])['tds_per_reception'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_df = qbs_df.drop(columns= ['player_id',\n",
    "                               'player_name',\n",
    "                               'position', \n",
    "                               'position_group',\n",
    "                               'headshot_url',\n",
    "                               'season_type',   \n",
    "                               'passing_epa',\n",
    "                               'pacr',\n",
    "                               'dakota',\n",
    "                               'attempts',\n",
    "                               'completions',\n",
    "                               'passing_yards',\n",
    "                               'passing_tds',\n",
    "                               'interceptions',\n",
    "                               'sacks',\n",
    "                               'sack_yards',\n",
    "                               'sack_fumbles',\n",
    "                               'sack_fumbles_lost',\n",
    "                               'passing_air_yards',\n",
    "                               'passing_yards_after_catch',\n",
    "                               'passing_first_downs',\n",
    "                               'passing_epa',\n",
    "                               'passing_2pt_conversions',\n",
    "                               'carries',\n",
    "                               'rushing_yards',\n",
    "                               'rushing_tds',\n",
    "                               'rushing_fumbles',\n",
    "                               'rushing_fumbles_lost',\n",
    "                               'rushing_first_downs',\n",
    "                               'rushing_epa',\n",
    "                               'rushing_2pt_conversions',\n",
    "                               'receptions',\n",
    "                               'targets',\n",
    "                               'receiving_yards',\n",
    "                               'receiving_tds',\n",
    "                               'receiving_fumbles',\n",
    "                               'receiving_fumbles_lost',\n",
    "                               'receiving_air_yards',\n",
    "                               'receiving_yards_after_catch',\n",
    "                               'receiving_first_downs',\n",
    "                               'receiving_epa',\n",
    "                               'receiving_2pt_conversions',\n",
    "                               'racr',\n",
    "                               'target_share',\n",
    "                               'air_yards_share',\n",
    "                               'wopr',\n",
    "                               'special_teams_tds',\n",
    "                               'fantasy_points',\n",
    "                               'fantasy_points_ppr'\n",
    "                              ]).reset_index(drop=True)\n",
    "qbs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the maximum week for each player\n",
    "max_week_idx = qbs_df.groupby(['player_display_name', 'season'])['week'].idxmax()\n",
    "\n",
    "# Select the rows corresponding to these indices\n",
    "qbs_df = qbs_df.loc[max_week_idx].reset_index(drop=True)\n",
    "qbs_df = qbs_df.drop(columns= 'week')\n",
    "qbs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_df = qbs_df.dropna(subset=['completion_percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_df = qbs_df[qbs_df['season_pass_attempts'] >= 100]\n",
    "qbs_df.drop(columns=['recent_team', 'opponent_team', 'completion_percentage', 'yards_per_attempt', 'pass_tds_per_attempt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbs_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rushers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df = rushers_df.drop(columns= ['player_id',\n",
    "                                       'player_name',\n",
    "                                       'position', \n",
    "                                       'position_group',\n",
    "                                       'headshot_url',\n",
    "                                       'season_type',\n",
    "                                       'passing_epa',\n",
    "                                       'pacr',\n",
    "                                       'dakota',\n",
    "                                       'completions',\n",
    "                                       'attempts',\n",
    "                                       'passing_yards',\n",
    "                                       'passing_tds',\n",
    "                                       'interceptions',\n",
    "                                       'sacks',\n",
    "                                       'sack_yards',\n",
    "                                       'sack_fumbles',\n",
    "                                       'sack_fumbles_lost',\n",
    "                                       'passing_air_yards',\n",
    "                                       'passing_yards_after_catch',\n",
    "                                       'passing_first_downs',\n",
    "                                       'passing_epa',\n",
    "                                       'passing_2pt_conversions',\n",
    "                                       'rushing_epa',\n",
    "                                       'receptions',\n",
    "                                       'targets',\n",
    "                                       'receiving_yards',\n",
    "                                       'receiving_tds',\n",
    "                                       'receiving_fumbles',\n",
    "                                       'receiving_fumbles_lost',\n",
    "                                       'receiving_air_yards',\n",
    "                                       'receiving_yards_after_catch',\n",
    "                                       'receiving_first_downs',\n",
    "                                       'receiving_epa',\n",
    "                                       'receiving_2pt_conversions',\n",
    "                                       'racr',\n",
    "                                       'target_share',\n",
    "                                       'air_yards_share',\n",
    "                                       'wopr',\n",
    "                                       'special_teams_tds',\n",
    "                                       'fantasy_points',\n",
    "                                       'fantasy_points_ppr'\n",
    "                                      ]).reset_index(drop=True)\n",
    "\n",
    "rushers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the maximum week for each player\n",
    "max_week_idx = rushers_df.groupby(['player_display_name', 'season'])['week'].idxmax()\n",
    "\n",
    "# Select the rows corresponding to these indices\n",
    "rushers_df = rushers_df.loc[max_week_idx].reset_index(drop=True)\n",
    "rushers_df = rushers_df.drop(columns= 'week')\n",
    "rushers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df = rushers_df[rushers_df['season_carries'] >= 100]\n",
    "rushers_df.drop(columns=['recent_team', 'opponent_team', 'carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost', 'rushing_first_downs', 'rushing_2pt_conversions', 'yards_per_carry', 'tds_per_carry'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df = receivers_df.drop(columns= ['player_id',\n",
    "                                           'player_name',\n",
    "                                           'position', \n",
    "                                           'position_group',\n",
    "                                           'headshot_url',\n",
    "                                           'season_type',\n",
    "                                           'passing_epa',\n",
    "                                           'pacr',\n",
    "                                           'dakota',\n",
    "                                           'completions',\n",
    "                                           'attempts',\n",
    "                                           'passing_yards',\n",
    "                                           'passing_tds',\n",
    "                                           'interceptions',\n",
    "                                           'sacks',\n",
    "                                           'sack_yards',\n",
    "                                           'sack_fumbles',\n",
    "                                           'sack_fumbles_lost',\n",
    "                                           'passing_air_yards',\n",
    "                                           'passing_yards_after_catch',\n",
    "                                           'passing_first_downs',\n",
    "                                           'passing_epa',\n",
    "                                           'passing_2pt_conversions',\n",
    "                                           'carries',\n",
    "                                           'rushing_yards',\n",
    "                                           'rushing_tds',\n",
    "                                           'rushing_fumbles',\n",
    "                                           'rushing_fumbles_lost',\n",
    "                                           'rushing_first_downs',\n",
    "                                           'rushing_epa',\n",
    "                                           'rushing_2pt_conversions',\n",
    "                                           'receiving_epa',\n",
    "                                           'racr',\n",
    "                                           'target_share',\n",
    "                                           'air_yards_share',\n",
    "                                           'wopr',\n",
    "                                           'special_teams_tds',\n",
    "                                           'fantasy_points',\n",
    "                                           'fantasy_points_ppr'\n",
    "                                          ]).reset_index(drop=True)\n",
    "\n",
    "receivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index of the maximum week for each player\n",
    "max_week_idx = receivers_df.groupby(['player_display_name', 'season'])['week'].idxmax()\n",
    "\n",
    "# Select the rows corresponding to these indices\n",
    "receivers_df = receivers_df.loc[max_week_idx].reset_index(drop=True)\n",
    "receivers_df = receivers_df.drop(columns= 'week')\n",
    "receivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df = receivers_df[receivers_df['season_receptions'] >= 75]\n",
    "receivers_df.drop(columns=['recent_team', 'opponent_team', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost', 'receiving_air_yards', 'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_2pt_conversions', 'yards_per_reception', 'tds_per_reception'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with Qbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (excluding the target and the player name)\n",
    "X = qbs_df[['season', 'season_passing_yards', 'season_pass_attempts', \n",
    "            'season_completion_percentage', 'season_yards_per_attempt', \n",
    "            'season_pass_tds_per_attempt']]\n",
    "# Target variable\n",
    "y = qbs_df['season_passing_tds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dummy model\n",
    "dummy_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Train the model\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_dummy_pred = dummy_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "dummy_mse = mean_squared_error(y_test, y_dummy_pred)\n",
    "print(f'Dummy Model Mean Squared Error: {dummy_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "tree_mse = mean_squared_error(y_test, y_tree_pred)\n",
    "print(f'Decision Tree Model Mean Squared Error: {tree_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances = tree_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importances_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with RandomForest\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validated Mean Squared Error: {-cv_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire dataset\n",
    "rf_model.fit(X_train, y_train)\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters found: {best_params}')\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "importances_best = best_rf_model.feature_importances_\n",
    "feature_importances_best_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances_best\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_best_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best model\n",
    "y_best_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "best_mse = mean_squared_error(y_test, y_best_pred)\n",
    "best_rmse = mean_squared_error(y_test, y_best_pred, squared=False)\n",
    "best_mae = mean_absolute_error(y_test, y_best_pred)\n",
    "best_r2 = r2_score(y_test, y_best_pred)\n",
    "\n",
    "print(f'Best Random Forest Model Mean Squared Error (MSE): {best_mse}')\n",
    "print(f'Best Random Forest Model Root Mean Squared Error (RMSE): {best_rmse}')\n",
    "print(f'Best Random Forest Model Mean Absolute Error (MAE): {best_mae}')\n",
    "print(f'Best Random Forest Model R-squared (R²): {best_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the overwhelmingly most important thing to a QB getting the most touchdowns in a season is getting the most passing yards in a season therefore our reccomendations will be the top QB in passing yards and TDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rushers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rushers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (excluding the target and the player name)\n",
    "X1 = rushers_df[['season', 'season_rushing_yards', 'season_carries', \n",
    "            'season_yards_per_carry', 'season_tds_per_carry']]\n",
    "# Target variable\n",
    "y1 = rushers_df['season_rushing_tds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dummy model\n",
    "dummy1_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Train the model\n",
    "dummy1_model.fit(X1_train, y1_train)\n",
    "\n",
    "# Make predictions\n",
    "y1_dummy_pred = dummy1_model.predict(X1_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "dummy1_mse = mean_squared_error(y1_test, y1_dummy_pred)\n",
    "print(f'Dummy Model Mean Squared Error: {dummy1_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree model\n",
    "tree_model1 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "tree_model1.fit(X1_train, y1_train)\n",
    "\n",
    "# Make predictions\n",
    "y1_tree_pred = tree_model1.predict(X1_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "tree_mse1 = mean_squared_error(y1_test, y1_tree_pred)\n",
    "print(f'Decision Tree Model Mean Squared Error: {tree_mse1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances1 = tree_model1.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importances1_df = pd.DataFrame({\n",
    "    'Feature': X1.columns,\n",
    "    'Importance': feature_importances1\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importances1_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with RandomForest\n",
    "rf_model1 = RandomForestRegressor(random_state=42)\n",
    "cv_scores1 = cross_val_score(rf_model1, X1_train, y1_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validated Mean Squared Error: {-cv_scores1.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire dataset\n",
    "rf_model1.fit(X1_train, y1_train)\n",
    "importances1 = rf_model1.feature_importances_\n",
    "feature_importances1_df = pd.DataFrame({\n",
    "    'Feature': X1.columns,\n",
    "    'Importance': importances1\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid search\n",
    "grid_search1 = GridSearchCV(estimator=rf_model1, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the grid search\n",
    "grid_search1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params1 = grid_search1.best_params_\n",
    "print(f'Best parameters found: {best_params1}')\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_model1 = grid_search1.best_estimator_\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_rf_model1.fit(X1_train, y1_train)\n",
    "importances_best1 = best_rf_model1.feature_importances_\n",
    "feature_importances_best_df1 = pd.DataFrame({\n",
    "    'Feature': X1.columns,\n",
    "    'Importance': importances_best1\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_best_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best model\n",
    "y1_best_pred = best_rf_model1.predict(X1_test)\n",
    "\n",
    "# Calculate metrics\n",
    "best_mse1 = mean_squared_error(y1_test, y1_best_pred)\n",
    "best_rmse1 = mean_squared_error(y1_test, y1_best_pred, squared=False)\n",
    "best_mae1 = mean_absolute_error(y1_test, y1_best_pred)\n",
    "best_r21 = r2_score(y1_test, y1_best_pred)\n",
    "\n",
    "print(f'Best Random Forest Model Mean Squared Error (MSE): {best_mse1}')\n",
    "print(f'Best Random Forest Model Root Mean Squared Error (RMSE): {best_rmse1}')\n",
    "print(f'Best Random Forest Model Mean Absolute Error (MAE): {best_mae1}')\n",
    "print(f'Best Random Forest Model R-squared (R²): {best_r21}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tds per carry and total yards no suprise there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receivers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (excluding the target and the player name)\n",
    "X2 = receivers_df[['season', 'season_receiving_yards', 'season_receptions', \n",
    "            'season_yards_per_reception', 'season_tds_per_reception']]\n",
    "# Target variable\n",
    "y2 = receivers_df['season_receiving_tds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dummy model\n",
    "dummy2_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "# Train the model\n",
    "dummy2_model.fit(X2_train, y2_train)\n",
    "\n",
    "# Make predictions\n",
    "y2_dummy_pred = dummy2_model.predict(X2_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "dummy2_mse = mean_squared_error(y2_test, y2_dummy_pred)\n",
    "print(f'Dummy Model Mean Squared Error: {dummy2_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decision tree model\n",
    "tree_model2 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "tree_model2.fit(X2_train, y2_train)\n",
    "\n",
    "# Make predictions\n",
    "y2_tree_pred = tree_model2.predict(X2_test)\n",
    "\n",
    "# Calculate mean squared error\n",
    "tree_mse2 = mean_squared_error(y2_test, y2_tree_pred)\n",
    "print(f'Decision Tree Model Mean Squared Error: {tree_mse2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances\n",
    "feature_importances2 = tree_model2.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importances2_df = pd.DataFrame({\n",
    "    'Feature': X2.columns,\n",
    "    'Importance': feature_importances2\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importances2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with RandomForest\n",
    "rf_model2 = RandomForestRegressor(random_state=42)\n",
    "cv_scores2 = cross_val_score(rf_model2, X2_train, y2_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'Cross-validated Mean Squared Error: {-cv_scores2.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the entire dataset\n",
    "rf_model2.fit(X2_train, y2_train)\n",
    "importances2 = rf_model2.feature_importances_\n",
    "feature_importances2_df = pd.DataFrame({\n",
    "    'Feature': X2.columns,\n",
    "    'Importance': importances2\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid search\n",
    "grid_search2 = GridSearchCV(estimator=rf_model2, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the grid search\n",
    "grid_search2.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params2 = grid_search2.best_params_\n",
    "print(f'Best parameters found: {best_params2}')\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_model2 = grid_search2.best_estimator_\n",
    "\n",
    "# Train the best model on the entire dataset\n",
    "best_rf_model2.fit(X2_train, y2_train)\n",
    "importances_best2 = best_rf_model2.feature_importances_\n",
    "feature_importances_best_df2 = pd.DataFrame({\n",
    "    'Feature': X2.columns,\n",
    "    'Importance': importances_best2\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances_best_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best model\n",
    "y2_best_pred = best_rf_model2.predict(X2_test)\n",
    "\n",
    "# Calculate metrics\n",
    "best_mse2 = mean_squared_error(y2_test, y2_best_pred)\n",
    "best_rmse2 = mean_squared_error(y2_test, y2_best_pred, squared=False)\n",
    "best_mae2 = mean_absolute_error(y2_test, y2_best_pred)\n",
    "best_r22 = r2_score(y2_test, y2_best_pred)\n",
    "\n",
    "print(f'Best Random Forest Model Mean Squared Error (MSE): {best_mse2}')\n",
    "print(f'Best Random Forest Model Root Mean Squared Error (RMSE): {best_rmse2}')\n",
    "print(f'Best Random Forest Model Mean Absolute Error (MAE): {best_mae2}')\n",
    "print(f'Best Random Forest Model R-squared (R²): {best_r22}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tds per reception and yards again. similar to rbs "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
